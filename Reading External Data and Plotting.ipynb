{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89545af-71ca-4ce7-999e-761366d7628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c4f99-90cc-4359-b9ab-d2d367b488d9",
   "metadata": {},
   "source": [
    "Pandas can easily read data stored in different file formats like CSV, JSON, XML or even Excel. Parsing always involves specifying the correct structure, encoding and other details. The `read_csv` method reads CSV files and accepts many parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ca595d-751b-4791-b308-3947ec554e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msep\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mheader\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"int | Sequence[int] | None | Literal['infer']\"\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnames\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Sequence[Hashable] | None | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'IndexLabel | Literal[False] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0musecols\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'list[HashableT] | Callable[[Hashable], bool] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DtypeArg | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'CSVEngine | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Mapping[Hashable, Callable] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'list | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'list | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'list[int] | int | Callable[[Hashable], bool] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Sequence[str] | Mapping[str, Sequence[str]] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskip_blank_lines\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | Sequence[Hashable] | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep_date_col\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Callable | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdate_format\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcache_dates\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'CompressionOptions'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\"'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mencoding_errors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'strict'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | csv.Dialect | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mon_bad_lines\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmemory_map\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfloat_precision\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Literal['high', 'legacy'] | None\"\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'StorageOptions | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype_backend\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DtypeBackend | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame | TextFileReader'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Read a comma-separated values (csv) file into DataFrame.\n",
       "\n",
       "Also supports optionally iterating or breaking of the file\n",
       "into chunks.\n",
       "\n",
       "Additional help can be found in the online docs for\n",
       "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filepath_or_buffer : str, path object or file-like object\n",
       "    Any valid string path is acceptable. The string could be a URL. Valid\n",
       "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
       "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
       "\n",
       "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
       "\n",
       "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
       "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
       "sep : str, default ','\n",
       "    Character or regex pattern to treat as the delimiter. If ``sep=None``, the\n",
       "    C engine cannot automatically detect\n",
       "    the separator, but the Python parsing engine can, meaning the latter will\n",
       "    be used and automatically detect the separator from only the first valid\n",
       "    row of the file by Python's builtin sniffer tool, ``csv.Sniffer``.\n",
       "    In addition, separators longer than 1 character and different from\n",
       "    ``'\\s+'`` will be interpreted as regular expressions and will also force\n",
       "    the use of the Python parsing engine. Note that regex delimiters are prone\n",
       "    to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
       "delimiter : str, optional\n",
       "    Alias for ``sep``.\n",
       "header : int, Sequence of int, 'infer' or None, default 'infer'\n",
       "    Row number(s) containing column labels and marking the start of the\n",
       "    data (zero-indexed). Default behavior is to infer the column names: if no ``names``\n",
       "    are passed the behavior is identical to ``header=0`` and column\n",
       "    names are inferred from the first line of the file, if column\n",
       "    names are passed explicitly to ``names`` then the behavior is identical to\n",
       "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
       "    replace existing names. The header can be a list of integers that\n",
       "    specify row locations for a :class:`~pandas.MultiIndex` on the columns\n",
       "    e.g. ``[0, 1, 3]``. Intervening rows that are not specified will be\n",
       "    skipped (e.g. 2 in this example is skipped). Note that this\n",
       "    parameter ignores commented lines and empty lines if\n",
       "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
       "    data rather than the first line of the file.\n",
       "names : Sequence of Hashable, optional\n",
       "    Sequence of column labels to apply. If the file contains a header row,\n",
       "    then you should explicitly pass ``header=0`` to override the column names.\n",
       "    Duplicates in this list are not allowed.\n",
       "index_col : Hashable, Sequence of Hashable or False, optional\n",
       "  Column(s) to use as row label(s), denoted either by column labels or column\n",
       "  indices.  If a sequence of labels or indices is given, :class:`~pandas.MultiIndex`\n",
       "  will be formed for the row labels.\n",
       "\n",
       "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
       "  column as the index, e.g., when you have a malformed file with delimiters at\n",
       "  the end of each line.\n",
       "usecols : list of Hashable or Callable, optional\n",
       "    Subset of columns to select, denoted either by column labels or column indices.\n",
       "    If list-like, all elements must either\n",
       "    be positional (i.e. integer indices into the document columns) or strings\n",
       "    that correspond to column names provided either by the user in ``names`` or\n",
       "    inferred from the document header row(s). If ``names`` are given, the document\n",
       "    header row(s) are not taken into account. For example, a valid list-like\n",
       "    ``usecols`` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
       "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
       "    To instantiate a :class:`~pandas.DataFrame` from ``data`` with element order\n",
       "    preserved use ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]``\n",
       "    for columns in ``['foo', 'bar']`` order or\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
       "    for ``['bar', 'foo']`` order.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the column\n",
       "    names, returning names where the callable function evaluates to ``True``. An\n",
       "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
       "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
       "    parsing time and lower memory usage.\n",
       "dtype : dtype or dict of {Hashable : dtype}, optional\n",
       "    Data type(s) to apply to either the whole dataset or individual columns.\n",
       "    E.g., ``{'a': np.float64, 'b': np.int32, 'c': 'Int64'}``\n",
       "    Use ``str`` or ``object`` together with suitable ``na_values`` settings\n",
       "    to preserve and not interpret ``dtype``.\n",
       "    If ``converters`` are specified, they will be applied INSTEAD\n",
       "    of ``dtype`` conversion.\n",
       "\n",
       "    .. versionadded:: 1.5.0\n",
       "\n",
       "        Support for ``defaultdict`` was added. Specify a ``defaultdict`` as input where\n",
       "        the default determines the ``dtype`` of the columns which are not explicitly\n",
       "        listed.\n",
       "engine : {'c', 'python', 'pyarrow'}, optional\n",
       "    Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
       "    is currently more feature-complete. Multithreading is currently only supported by\n",
       "    the pyarrow engine.\n",
       "\n",
       "    .. versionadded:: 1.4.0\n",
       "\n",
       "        The 'pyarrow' engine was added as an *experimental* engine, and some features\n",
       "        are unsupported, or may not work correctly, with this engine.\n",
       "converters : dict of {Hashable : Callable}, optional\n",
       "    Functions for converting values in specified columns. Keys can either\n",
       "    be column labels or column indices.\n",
       "true_values : list, optional\n",
       "    Values to consider as ``True`` in addition to case-insensitive variants of 'True'.\n",
       "false_values : list, optional\n",
       "    Values to consider as ``False`` in addition to case-insensitive variants of 'False'.\n",
       "skipinitialspace : bool, default False\n",
       "    Skip spaces after delimiter.\n",
       "skiprows : int, list of int or Callable, optional\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (``int``)\n",
       "    at the start of the file.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the row\n",
       "    indices, returning ``True`` if the row should be skipped and ``False`` otherwise.\n",
       "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
       "skipfooter : int, default 0\n",
       "    Number of lines at bottom of file to skip (Unsupported with ``engine='c'``).\n",
       "nrows : int, optional\n",
       "    Number of rows of file to read. Useful for reading pieces of large files.\n",
       "na_values : Hashable, Iterable of Hashable or dict of {Hashable : Iterable}, optional\n",
       "    Additional strings to recognize as ``NA``/``NaN``. If ``dict`` passed, specific\n",
       "    per-column ``NA`` values.  By default the following values are interpreted as\n",
       "    ``NaN``: \" \", \"#N/A\", \"#N/A N/A\", \"#NA\", \"-1.#IND\", \"-1.#QNAN\", \"-NaN\", \"-nan\",\n",
       "    \"1.#IND\", \"1.#QNAN\", \"<NA>\", \"N/A\", \"NA\", \"NULL\", \"NaN\", \"None\",\n",
       "    \"n/a\", \"nan\", \"null \".\n",
       "\n",
       "keep_default_na : bool, default True\n",
       "    Whether or not to include the default ``NaN`` values when parsing the data.\n",
       "    Depending on whether ``na_values`` is passed in, the behavior is as follows:\n",
       "\n",
       "    * If ``keep_default_na`` is ``True``, and ``na_values`` are specified, ``na_values``\n",
       "      is appended to the default ``NaN`` values used for parsing.\n",
       "    * If ``keep_default_na`` is ``True``, and ``na_values`` are not specified, only\n",
       "      the default ``NaN`` values are used for parsing.\n",
       "    * If ``keep_default_na`` is ``False``, and ``na_values`` are specified, only\n",
       "      the ``NaN`` values specified ``na_values`` are used for parsing.\n",
       "    * If ``keep_default_na`` is ``False``, and ``na_values`` are not specified, no\n",
       "      strings will be parsed as ``NaN``.\n",
       "\n",
       "    Note that if ``na_filter`` is passed in as ``False``, the ``keep_default_na`` and\n",
       "    ``na_values`` parameters will be ignored.\n",
       "na_filter : bool, default True\n",
       "    Detect missing value markers (empty strings and the value of ``na_values``). In\n",
       "    data without any ``NA`` values, passing ``na_filter=False`` can improve the\n",
       "    performance of reading a large file.\n",
       "verbose : bool, default False\n",
       "    Indicate number of ``NA`` values placed in non-numeric columns.\n",
       "skip_blank_lines : bool, default True\n",
       "    If ``True``, skip over blank lines rather than interpreting as ``NaN`` values.\n",
       "parse_dates : bool, list of Hashable, list of lists or dict of {Hashable : list}, default False\n",
       "    The behavior is as follows:\n",
       "\n",
       "    * ``bool``. If ``True`` -> try parsing the index.\n",
       "    * ``list`` of ``int`` or names. e.g. If ``[1, 2, 3]`` -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * ``list`` of ``list``. e.g.  If ``[[1, 3]]`` -> combine columns 1 and 3 and parse\n",
       "      as a single date column.\n",
       "    * ``dict``, e.g. ``{'foo' : [1, 3]}`` -> parse columns 1, 3 as date and call\n",
       "      result 'foo'\n",
       "\n",
       "    If a column or index cannot be represented as an array of ``datetime``,\n",
       "    say because of an unparsable value or a mixture of timezones, the column\n",
       "    or index will be returned unaltered as an ``object`` data type. For\n",
       "    non-standard ``datetime`` parsing, use :func:`~pandas.to_datetime` after\n",
       "    :func:`~pandas.read_csv`.\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "infer_datetime_format : bool, default False\n",
       "    If ``True`` and ``parse_dates`` is enabled, pandas will attempt to infer the\n",
       "    format of the ``datetime`` strings in the columns, and if it can be inferred,\n",
       "    switch to a faster method of parsing them. In some cases this can increase\n",
       "    the parsing speed by 5-10x.\n",
       "\n",
       "    .. deprecated:: 2.0.0\n",
       "        A strict version of this argument is now the default, passing it has no effect.\n",
       "\n",
       "keep_date_col : bool, default False\n",
       "    If ``True`` and ``parse_dates`` specifies combining multiple columns then\n",
       "    keep the original columns.\n",
       "date_parser : Callable, optional\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    ``datetime`` instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. pandas will try to call ``date_parser`` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by ``parse_dates``) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by ``parse_dates`` into a single array\n",
       "    and pass that; and 3) call ``date_parser`` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by ``parse_dates``) as\n",
       "    arguments.\n",
       "\n",
       "    .. deprecated:: 2.0.0\n",
       "       Use ``date_format`` instead, or read in as ``object`` and then apply\n",
       "       :func:`~pandas.to_datetime` as-needed.\n",
       "date_format : str or dict of column -> format, optional\n",
       "   Format to use for parsing dates when used in conjunction with ``parse_dates``.\n",
       "   For anything more complex, please read in as ``object`` and then apply\n",
       "   :func:`~pandas.to_datetime` as-needed.\n",
       "\n",
       "   .. versionadded:: 2.0.0\n",
       "dayfirst : bool, default False\n",
       "    DD/MM format dates, international and European format.\n",
       "cache_dates : bool, default True\n",
       "    If ``True``, use a cache of unique, converted dates to apply the ``datetime``\n",
       "    conversion. May produce significant speed-up when parsing duplicate\n",
       "    date strings, especially ones with timezone offsets.\n",
       "\n",
       "iterator : bool, default False\n",
       "    Return ``TextFileReader`` object for iteration or getting chunks with\n",
       "    ``get_chunk()``.\n",
       "\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "       ``TextFileReader`` is a context manager.\n",
       "chunksize : int, optional\n",
       "    Number of lines to read from the file per chunk. Passing a value will cause the\n",
       "    function to return a ``TextFileReader`` object for iteration.\n",
       "    See the `IO Tools docs\n",
       "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
       "    for more information on ``iterator`` and ``chunksize``.\n",
       "\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "       ``TextFileReader`` is a context manager.\n",
       "compression : str or dict, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
       "    path-like, then detect compression from the following extensions: '.gz',\n",
       "    '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
       "    (otherwise no compression).\n",
       "    If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
       "    Set to ``None`` for no decompression.\n",
       "    Can also be a dict with key ``'method'`` set\n",
       "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
       "    other key-value pairs are forwarded to\n",
       "    ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
       "    ``bz2.BZ2File``, ``zstandard.ZstdDecompressor``, ``lzma.LZMAFile`` or\n",
       "    ``tarfile.TarFile``, respectively.\n",
       "    As an example, the following could be passed for Zstandard decompression using a\n",
       "    custom compression dictionary:\n",
       "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
       "\n",
       "    .. versionadded:: 1.5.0\n",
       "        Added support for `.tar` files.\n",
       "\n",
       "    .. versionchanged:: 1.4.0 Zstandard support.\n",
       "\n",
       "thousands : str (length 1), optional\n",
       "    Character acting as the thousands separator in numerical values.\n",
       "decimal : str (length 1), default '.'\n",
       "    Character to recognize as decimal point (e.g., use ',' for European data).\n",
       "lineterminator : str (length 1), optional\n",
       "    Character used to denote a line break. Only valid with C parser.\n",
       "quotechar : str (length 1), optional\n",
       "    Character used to denote the start and end of a quoted item. Quoted\n",
       "    items can include the ``delimiter`` and it will be ignored.\n",
       "quoting : {0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL\n",
       "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Default is\n",
       "    ``csv.QUOTE_MINIMAL`` (i.e., 0) which implies that only fields containing special\n",
       "    characters are quoted (e.g., characters defined in ``quotechar``, ``delimiter``,\n",
       "    or ``lineterminator``.\n",
       "doublequote : bool, default True\n",
       "   When ``quotechar`` is specified and ``quoting`` is not ``QUOTE_NONE``, indicate\n",
       "   whether or not to interpret two consecutive ``quotechar`` elements INSIDE a\n",
       "   field as a single ``quotechar`` element.\n",
       "escapechar : str (length 1), optional\n",
       "    Character used to escape other characters.\n",
       "comment : str (length 1), optional\n",
       "    Character indicating that the remainder of line should not be parsed.\n",
       "    If found at the beginning\n",
       "    of a line, the line will be ignored altogether. This parameter must be a\n",
       "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
       "    fully commented lines are ignored by the parameter ``header`` but not by\n",
       "    ``skiprows``. For example, if ``comment='#'``, parsing\n",
       "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in ``'a,b,c'`` being\n",
       "    treated as the header.\n",
       "encoding : str, optional, default 'utf-8'\n",
       "    Encoding to use for UTF when reading/writing (ex. ``'utf-8'``). `List of Python\n",
       "    standard encodings\n",
       "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
       "\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "       When ``encoding`` is ``None``, ``errors='replace'`` is passed to\n",
       "       ``open()``. Otherwise, ``errors='strict'`` is passed to ``open()``.\n",
       "       This behavior was previously only the case for ``engine='python'``.\n",
       "\n",
       "    .. versionchanged:: 1.3.0\n",
       "\n",
       "       ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
       "       influence on how encoding errors are handled.\n",
       "\n",
       "encoding_errors : str, optional, default 'strict'\n",
       "    How encoding errors are treated. `List of possible values\n",
       "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
       "\n",
       "    .. versionadded:: 1.3.0\n",
       "\n",
       "dialect : str or csv.Dialect, optional\n",
       "    If provided, this parameter will override values (default or not) for the\n",
       "    following parameters: ``delimiter``, ``doublequote``, ``escapechar``,\n",
       "    ``skipinitialspace``, ``quotechar``, and ``quoting``. If it is necessary to\n",
       "    override values, a ``ParserWarning`` will be issued. See ``csv.Dialect``\n",
       "    documentation for more details.\n",
       "on_bad_lines : {'error', 'warn', 'skip'} or Callable, default 'error'\n",
       "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
       "    Allowed values are :\n",
       "\n",
       "    - ``'error'``, raise an Exception when a bad line is encountered.\n",
       "    - ``'warn'``, raise a warning when a bad line is encountered and skip that line.\n",
       "    - ``'skip'``, skip bad lines without raising or warning when they are encountered.\n",
       "\n",
       "    .. versionadded:: 1.3.0\n",
       "\n",
       "    .. versionadded:: 1.4.0\n",
       "\n",
       "        - Callable, function with signature\n",
       "          ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
       "          bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
       "          If the function returns ``None``, the bad line will be ignored.\n",
       "          If the function returns a new ``list`` of strings with more elements than\n",
       "          expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
       "          Only supported when ``engine='python'``\n",
       "\n",
       "delim_whitespace : bool, default False\n",
       "    Specifies whether or not whitespace (e.g. ``' '`` or ``'\\t'``) will be\n",
       "    used as the ``sep`` delimiter. Equivalent to setting ``sep='\\s+'``. If this option\n",
       "    is set to ``True``, nothing should be passed in for the ``delimiter``\n",
       "    parameter.\n",
       "low_memory : bool, default True\n",
       "    Internally process the file in chunks, resulting in lower memory use\n",
       "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
       "    types either set ``False``, or specify the type with the ``dtype`` parameter.\n",
       "    Note that the entire file is read into a single :class:`~pandas.DataFrame`\n",
       "    regardless, use the ``chunksize`` or ``iterator`` parameter to return the data in\n",
       "    chunks. (Only valid with C parser).\n",
       "memory_map : bool, default False\n",
       "    If a filepath is provided for ``filepath_or_buffer``, map the file object\n",
       "    directly onto memory and access the data directly from there. Using this\n",
       "    option can improve performance because there is no longer any I/O overhead.\n",
       "float_precision : {'high', 'legacy', 'round_trip'}, optional\n",
       "    Specifies which converter the C engine should use for floating-point\n",
       "    values. The options are ``None`` or ``'high'`` for the ordinary converter,\n",
       "    ``'legacy'`` for the original lower precision pandas converter, and\n",
       "    ``'round_trip'`` for the round-trip converter.\n",
       "\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "storage_options : dict, optional\n",
       "    Extra options that make sense for a particular storage connection, e.g.\n",
       "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
       "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
       "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
       "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
       "    details, and for more examples on storage options refer `here\n",
       "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
       "    highlight=storage_options#reading-writing-remote-files>`_.\n",
       "\n",
       "    .. versionadded:: 1.2\n",
       "\n",
       "dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
       "    Back-end data type applied to the resultant :class:`DataFrame`\n",
       "    (still experimental). Behaviour is as follows:\n",
       "\n",
       "    * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
       "      (default).\n",
       "    * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
       "      DataFrame.\n",
       "\n",
       "    .. versionadded:: 2.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or TextFileReader\n",
       "    A comma-separated values (csv) file is returned as two-dimensional\n",
       "    data structure with labeled axes.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
       "read_table : Read general delimited file into DataFrame.\n",
       "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\hp\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6849d726-86fa-458c-8748-75366ca1c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/btc-market-price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3306911f-5e70-4e6c-bd64-d8e7a2a537c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017-04-02 00:00:00</th>\n",
       "      <th>1099.169125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-03 00:00:00</td>\n",
       "      <td>1141.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-04 00:00:00</td>\n",
       "      <td>1141.600363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-05 00:00:00</td>\n",
       "      <td>1133.079314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-06 00:00:00</td>\n",
       "      <td>1196.307937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-07 00:00:00</td>\n",
       "      <td>1190.454250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2017-04-02 00:00:00  1099.169125\n",
       "0  2017-04-03 00:00:00  1141.813000\n",
       "1  2017-04-04 00:00:00  1141.600363\n",
       "2  2017-04-05 00:00:00  1133.079314\n",
       "3  2017-04-06 00:00:00  1196.307937\n",
       "4  2017-04-07 00:00:00  1190.454250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e6bb26-4e7f-40bc-a91c-e191a1cf2d83",
   "metadata": {},
   "source": [
    "The CSV file we're reading has only two columns: `timestamp` and `price`. It doesn't have a header, it contains whitespaces and has values separated by commas. pandas automatically assigned the first row of data as headers, which is incorrect. We can overwrite this behavior with the `header` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d86abf-77d8-474f-b7a7-0c52b471b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/btc-market-price.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b84c3c27-5d03-4773-b70b-adaf2ab03012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-02 00:00:00</td>\n",
       "      <td>1099.169125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-03 00:00:00</td>\n",
       "      <td>1141.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-04 00:00:00</td>\n",
       "      <td>1141.600363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-05 00:00:00</td>\n",
       "      <td>1133.079314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-06 00:00:00</td>\n",
       "      <td>1196.307937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1\n",
       "0  2017-04-02 00:00:00  1099.169125\n",
       "1  2017-04-03 00:00:00  1141.813000\n",
       "2  2017-04-04 00:00:00  1141.600363\n",
       "3  2017-04-05 00:00:00  1133.079314\n",
       "4  2017-04-06 00:00:00  1196.307937"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158994c5-5c6d-46ce-a0cc-3738ddcd4a3a",
   "metadata": {},
   "source": [
    "We can then set the names of each column explicitely by setting the `df.columns` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b969ee5-6a99-4c25-a753-5ae6e5f83caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Timestamp', 'Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a135c4a-9ffc-4f0f-b224-b13e556c3e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "707828a7-7268-489e-b20e-64d8c0f39cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 365 entries, 0 to 364\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Timestamp  365 non-null    object \n",
      " 1   Price      365 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 5.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b997cc7e-5c35-4d01-89ab-90277cad4823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-02 00:00:00</td>\n",
       "      <td>1099.169125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-03 00:00:00</td>\n",
       "      <td>1141.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-04 00:00:00</td>\n",
       "      <td>1141.600363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-05 00:00:00</td>\n",
       "      <td>1133.079314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-06 00:00:00</td>\n",
       "      <td>1196.307937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp        Price\n",
       "0  2017-04-02 00:00:00  1099.169125\n",
       "1  2017-04-03 00:00:00  1141.813000\n",
       "2  2017-04-04 00:00:00  1141.600363\n",
       "3  2017-04-05 00:00:00  1133.079314\n",
       "4  2017-04-06 00:00:00  1196.307937"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bd34205-ce02-4da9-8078-3c50edc3a4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2018-03-30 00:00:00</td>\n",
       "      <td>6882.531667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2018-03-31 00:00:00</td>\n",
       "      <td>6935.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-04-01 00:00:00</td>\n",
       "      <td>6794.105000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp        Price\n",
       "362  2018-03-30 00:00:00  6882.531667\n",
       "363  2018-03-31 00:00:00  6935.480000\n",
       "364  2018-04-01 00:00:00  6794.105000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a7fdb-3f52-4393-81e2-17e37ef6d231",
   "metadata": {},
   "source": [
    "The type of the `Price` column was correctly interpreted as `float`, but the `Timestamp` was interpreted as a regular string (`object` in pandas notation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39c09b08-0442-4a8d-ac50-c5df3fdff85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp     object\n",
       "Price        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f11f24-4e4d-4e86-a83a-80b889f6c0ba",
   "metadata": {},
   "source": [
    "We can perform a vectorized operation to parse all the Timestamp values as `Datetime` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfaf784e-f7db-433b-bb72-864e0d7e95a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2017-04-02\n",
       "1   2017-04-03\n",
       "2   2017-04-04\n",
       "3   2017-04-05\n",
       "4   2017-04-06\n",
       "Name: Timestamp, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df['Timestamp']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aed5618c-377a-45e0-901d-a49188e19895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71b714e9-0be7-471a-a2ca-570e147fbd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>1099.169125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>1141.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>1141.600363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>1133.079314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>1196.307937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp        Price\n",
       "0 2017-04-02  1099.169125\n",
       "1 2017-04-03  1141.813000\n",
       "2 2017-04-04  1141.600363\n",
       "3 2017-04-05  1133.079314\n",
       "4 2017-04-06  1196.307937"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a17e24cf-c450-4db0-b8e9-66603cd08dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp    datetime64[ns]\n",
       "Price               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773a12f-cf1b-4d65-9a12-0c78cd24acf5",
   "metadata": {},
   "source": [
    "The timestamp looks a lot like the index of this `DataFrame`: `date > price`. We can change the autoincremental ID generated by pandas and use the `Timestamp DS` column as the Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63a9e3d9-6bec-46bc-b5fd-3b0dfe2e4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5f81f3e-774e-4883-9545-ee75442022df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-02</th>\n",
       "      <td>1099.169125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-03</th>\n",
       "      <td>1141.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-04</th>\n",
       "      <td>1141.600363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-05</th>\n",
       "      <td>1133.079314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-06</th>\n",
       "      <td>1196.307937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Price\n",
       "Timestamp              \n",
       "2017-04-02  1099.169125\n",
       "2017-04-03  1141.813000\n",
       "2017-04-04  1141.600363\n",
       "2017-04-05  1133.079314\n",
       "2017-04-06  1196.307937"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4976985d-b8ca-4be2-9667-eb0430c0497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price    4193.574667\n",
       "Name: 2017-09-29 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['2017-09-29']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650cc97a-c4f9-4fb1-bc55-20ac4621a9a0",
   "metadata": {},
   "source": [
    "## Putting everything together\n",
    "And now, we've finally arrived to the final, desired version of the `DataFrame` parsed from our CSV file. The steps were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "895eeb9f-197c-4f19-9785-d1896596c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/btc-market-price.csv', header=None)\n",
    "df.columns = ['Timestamp', 'Price']\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df.set_index('Timestamp', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4df2b40c-0db4-4369-b695-d83da445b6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-02</th>\n",
       "      <td>1099.169125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-03</th>\n",
       "      <td>1141.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-04</th>\n",
       "      <td>1141.600363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-05</th>\n",
       "      <td>1133.079314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-06</th>\n",
       "      <td>1196.307937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Price\n",
       "Timestamp              \n",
       "2017-04-02  1099.169125\n",
       "2017-04-03  1141.813000\n",
       "2017-04-04  1141.600363\n",
       "2017-04-05  1133.079314\n",
       "2017-04-06  1196.307937"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651d5ef6-5f04-40d7-8cf2-178601b3ce67",
   "metadata": {},
   "source": [
    "**There should be a better way**. And there is . And there usually is, explicitly with all these repetitive tasks with pandas.\n",
    "\n",
    "The `read_csv` function is extremely powerful and you can specify many more parameters at import time. We can achive the same results with only one line by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4c90e91-4cb0-4cfa-a3de-936cc1a5ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'data/btc-market-price.csv',\n",
    "    header=None,\n",
    "    names=['Timestamp', 'Price'],\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23b5b16e-2cce-41b0-ad66-af354cb7717b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-02</th>\n",
       "      <td>1099.169125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-03</th>\n",
       "      <td>1141.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-04</th>\n",
       "      <td>1141.600363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-05</th>\n",
       "      <td>1133.079314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-06</th>\n",
       "      <td>1196.307937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Price\n",
       "Timestamp              \n",
       "2017-04-02  1099.169125\n",
       "2017-04-03  1141.813000\n",
       "2017-04-04  1141.600363\n",
       "2017-04-05  1133.079314\n",
       "2017-04-06  1196.307937"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
